{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a68d9e8c-7b5c-4e78-8fa5-67fe13b8471b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**farmer**: can you give me some treatment recommendation for potato early blight disease in arabic language ?\n",
       "\n",
       "**AgriTech**: تreatment recommendations for potato early blight disease may vary depending on the severity, duration, and geographical location of the infestation. Here are some general treatment recommendations in Arabic:\n",
       "\n",
       "1. **استخدام الأسمدة**: Use fungicides containing copper, sulfur, or chlorothalonil to treat fungal infections.\n",
       "2. **الاستعمال من النباء**: Apply bactericides such as copper oxychloride or copper gluconate to control bacterial pathogens that may be involved in the disease process.\n",
       "3. **إستخدام الفيروسات**: Use antifungal agents like imizoxanil or chlorothalonil to treat fungal infections caused by fungi other than Phytophthora infestans, which causes early blight.\n",
       "4. **الاستعمال من الحشرات**: Apply insecticidal soap or neem oil to control aphids and other pests that may be affected by the disease.\n",
       "5. **تحليل الوضع الفعلي**: Conduct thorough analysis of the potato crop's condition, including soil temperature, moisture levels, and pest activity, to determine the best treatment strategy.\n",
       "\n",
       "Some recommended fungicides for early blight on potatoes in Arabic:\n",
       "\n",
       "* **إستخدام الأسمدة:**\n",
       " + بتراليم (Tricalcium aluminosilicate): 50 g/100 kg soil\n",
       " + كربونات المطاعم (Sodium carbamate): 0.5 g/100 kg soil\n",
       " + سيبرين (Copper oxychloride): 1.5 g/100 kg soil\n",
       "* **الاستعمال من النباء:**\n",
       " + كوباليديوم سيلوكريتات (Copper oxychloride): 0.05 g/10 L water\n",
       " + ليزيمون (Neem oil): 2,500 ppm\n",
       "\n",
       "**هيتم تحليل الوضع الفعلي وتحديد الوسيلة المناسبة للتreatment؟**\n",
       "\n",
       "It is essential to conduct a thorough analysis of the potato crop's condition and determine the best treatment strategy. This includes:\n",
       "\n",
       "* **التحليلات الإحصائية**: Collect data on soil temperature, moisture levels, and pest activity.\n",
       "* **التحليلات البيئية**: Assess the environmental conditions that may affect the disease's development.\n",
       "* **التجارب المناسبة**: Conduct experiments with different treatments to evaluate their efficacy and safety.\n",
       "\n",
       "**إستخدام فاكهة جديدة**: Consider using new or emerging treatments such as plant growth regulators, biological control agents, or innovative fungicides to address the growing resistance problem associated with early blight on potatoes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "farmer:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salam ya farmer!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import ollama  # Module to interact with the Ollama chat model\n",
    "from IPython.display import display, Markdown, clear_output  # Functions for displaying outputs in Jupyter notebooks\n",
    "\n",
    "# Function to stream responses from the AgriTech LLM\n",
    "def stream_AgriTech_response(prompt):\n",
    "    model = 'llama3.2:1b'  # Specify the model version to use\n",
    "    # Initiate a chat with the model using the provided prompt and enable streaming\n",
    "    stream = ollama.chat(model=model, messages=[{'role': 'user', 'content': prompt}], stream=True)\n",
    "    \n",
    "    # Yield each chunk of the model's response as it becomes available\n",
    "    for chunk in stream:\n",
    "        yield chunk['message']['content']\n",
    "\n",
    "# Function for continuous chatting\n",
    "def interactive_chat_streaming():\n",
    "    print(\"You can now chat with AgriTech LLM powered by LLama 3.2 Model made by Bahaa :)\")\n",
    "    print(\"Type 'exit' to stop chatting.\")\n",
    "    chat_history = []  # Initialize an empty list to store the chat history (temporary since no memory to store the chat)\n",
    "    \n",
    "    while True:\n",
    "        # Prompt the user (farmer) for input(so2al 3an disease lel crop)\n",
    "        user_input = input(\"farmer: \")\n",
    "\n",
    "        # etla3 bara loop law el user da5l kelmet exit\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"salam ya farmer!\") \n",
    "            break\n",
    "\n",
    "        # Append the user's input to the chat history\n",
    "        chat_history.append(f\"**farmer**: {user_input}\")\n",
    "\n",
    "        # Get the model's streaming response based on the user's input\n",
    "        stream = stream_AgriTech_response(user_input)\n",
    "        current_response = \"\"  # Initialize a variable to append the model's response\n",
    "\n",
    "        # Process and display the model's response in real-time\n",
    "        for chunk in stream:\n",
    "            current_response += chunk  # Append each chunk to the current response\n",
    "            \n",
    "            clear_output(wait=True)  # Clear the previous output to update the display\n",
    "            \n",
    "            # Combine the chat history with the current response\n",
    "            full_chat = \"\\n\\n\".join(chat_history) + f\"\\n\\n**AgriTech**: {current_response}\"\n",
    "            \n",
    "            display(Markdown(full_chat))  # Display the updated chat in Markdown format\n",
    "\n",
    "        # After the full response is received, add it to the chat history\n",
    "        chat_history.append(f\"**AgriTech**: {current_response}\")\n",
    "        clear_output(wait=True)  # Clear the output to refresh the display\n",
    "        display(Markdown(\"\\n\\n\".join(chat_history)))  # Display the complete chat history\n",
    "\n",
    "# Start the interactive chat session\n",
    "interactive_chat_streaming()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b04016-d163-4a60-b339-ffd703a21fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
